# 通过Web前端测试YOLOv8发网检测模型

本文档提供了如何通过Web前端测试新集成的YOLOv8发网检测模型的指南。

## 功能概述

我们已经将YOLOv8发网检测模型集成到了Web API中，并提供了专门的测试页面。通过这些更新，您可以：

1. 使用YOLOv8检测器进行发网检测
2. 通过Web界面上传图片进行测试
3. 查看检测结果和可视化输出
4. 获取检测器的详细信息

## 如何使用

### 启动API服务

1. 确保已经安装了所有必要的依赖
2. 设置环境变量以使用YOLOv8检测器（可选）：

```bash
# 设置使用YOLOv8检测器
export HAIRNET_DETECTOR_TYPE=yolo
# 设置模型路径（可选，有默认值）
export YOLO_MODEL_PATH=/path/to/your/model.pt
# 设置设备（可选，默认为自动选择）
export DEVICE=cuda
# 设置置信度阈值（可选，默认为0.5）
export CONFIDENCE_THRESHOLD=0.6
```

3. 启动API服务：

```bash
python -m uvicorn src.api.app:app --reload --host 0.0.0.0 --port 8000
```

### 访问测试页面

1. 打开浏览器，访问专门的YOLOv8测试页面：

```
http://localhost:8000/frontend/yolo_test.html
```

2. 页面将显示当前使用的检测器类型和相关信息

### 测试发网检测

1. 在测试页面上，点击上传区域或拖放图片到上传区域
2. 选择一张包含人物的图片（支持JPG和PNG格式）
3. 点击"开始检测"按钮
4. 等待检测完成，查看结果

## 检测结果说明

检测结果包括：

- 带有标注的结果图片
- 统计信息（检测到的人数、佩戴发网人数、未佩戴发网人数、合规率、平均置信度）
- 详细检测结果（每个检测到的人物的位置、是否佩戴发网、置信度等）

## API接口说明

### 1. 发网检测接口

- **URL**: `/api/v1/detect/hairnet`
- **方法**: POST
- **参数**: 图片文件（multipart/form-data）
- **返回**: JSON格式的检测结果和Base64编码的结果图片

### 2. API信息接口

- **URL**: `/api/v1/info`
- **方法**: GET
- **返回**: 包含API信息和当前检测器信息的JSON数据

### 3. WebSocket实时检测

- **URL**: `/ws`
- **协议**: WebSocket
- **功能**: 支持实时视频流的发网检测

## 故障排除

如果遇到问题，请检查：

1. API服务是否正常运行
2. 环境变量是否正确设置
3. YOLOv8模型文件是否存在且路径正确
4. 浏览器控制台是否有错误信息

## 注意事项

- YOLOv8检测器需要较高的计算资源，建议在有GPU的环境中运行
- 图片大小会影响检测速度和准确率
- 如果检测结果不准确，可以尝试调整置信度阈值
