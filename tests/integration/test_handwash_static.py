#!/usr/bin/env python3
"""
é™æ€å›¾åƒæ‰‹éƒ¨æ´—æ‰‹æ£€æµ‹æµ‹è¯•è„šæœ¬
ä½¿ç”¨ç”Ÿæˆçš„æµ‹è¯•å›¾åƒè¿›è¡Œæ‰‹éƒ¨æ£€æµ‹æ¼”ç¤º
"""

import time

import cv2
import numpy as np

from src.core.behavior import BehaviorRecognizer
from src.core.detector import HumanDetector
from src.core.pose_detector import PoseDetector
from src.services.detection_service import DetectionResult


def create_test_image():
    """åˆ›å»ºä¸€ä¸ªåŒ…å«äººå½¢è½®å»“çš„æµ‹è¯•å›¾åƒ"""
    # åˆ›å»º640x480çš„ç™½è‰²èƒŒæ™¯å›¾åƒ
    img = np.ones((480, 640, 3), dtype=np.uint8) * 255

    # ç»˜åˆ¶ä¸€ä¸ªç®€å•çš„äººå½¢è½®å»“
    # å¤´éƒ¨
    cv2.circle(img, (320, 100), 40, (100, 100, 100), -1)

    # èº«ä½“
    cv2.rectangle(img, (280, 140), (360, 300), (100, 100, 100), -1)

    # å·¦è‡‚
    cv2.rectangle(img, (240, 160), (280, 280), (100, 100, 100), -1)

    # å³è‡‚
    cv2.rectangle(img, (360, 160), (400, 280), (100, 100, 100), -1)

    # å·¦è…¿
    cv2.rectangle(img, (290, 300), (320, 420), (100, 100, 100), -1)

    # å³è…¿
    cv2.rectangle(img, (340, 300), (370, 420), (100, 100, 100), -1)

    # æ·»åŠ ä¸€äº›å™ªå£°ä½¿å›¾åƒæ›´çœŸå®
    noise = np.random.randint(0, 50, img.shape, dtype=np.uint8)
    img = cv2.add(img, noise)

    return img


def draw_hand_keypoints_demo(frame, center_x, center_y, hand_label="Left"):
    """åœ¨æŒ‡å®šä½ç½®ç»˜åˆ¶æ¼”ç¤ºæ‰‹éƒ¨å…³é”®ç‚¹"""
    # æ¨¡æ‹Ÿ21ä¸ªæ‰‹éƒ¨å…³é”®ç‚¹çš„ç›¸å¯¹ä½ç½®
    hand_points = [
        (0, 0),  # 0: æ‰‹è…•
        (-10, -20),  # 1: æ‹‡æŒ‡æ ¹éƒ¨
        (-15, -35),  # 2: æ‹‡æŒ‡ä¸­é—´
        (-20, -45),  # 3: æ‹‡æŒ‡æŒ‡å°–
        (-25, -50),  # 4: æ‹‡æŒ‡å°–ç«¯
        (5, -25),  # 5: é£ŸæŒ‡æ ¹éƒ¨
        (8, -40),  # 6: é£ŸæŒ‡ä¸­é—´
        (10, -50),  # 7: é£ŸæŒ‡æŒ‡å°–
        (12, -55),  # 8: é£ŸæŒ‡å°–ç«¯
        (15, -20),  # 9: ä¸­æŒ‡æ ¹éƒ¨
        (18, -35),  # 10: ä¸­æŒ‡ä¸­é—´
        (20, -45),  # 11: ä¸­æŒ‡æŒ‡å°–
        (22, -50),  # 12: ä¸­æŒ‡å°–ç«¯
        (25, -15),  # 13: æ— åæŒ‡æ ¹éƒ¨
        (28, -25),  # 14: æ— åæŒ‡ä¸­é—´
        (30, -35),  # 15: æ— åæŒ‡æŒ‡å°–
        (32, -40),  # 16: æ— åæŒ‡å°–ç«¯
        (35, -10),  # 17: å°æŒ‡æ ¹éƒ¨
        (38, -18),  # 18: å°æŒ‡ä¸­é—´
        (40, -25),  # 19: å°æŒ‡æŒ‡å°–
        (42, -30),  # 20: å°æŒ‡å°–ç«¯
    ]

    # ç»˜åˆ¶æ‰‹éƒ¨è¾¹ç•Œæ¡†
    bbox_x1 = center_x - 30
    bbox_y1 = center_y - 60
    bbox_x2 = center_x + 50
    bbox_y2 = center_y + 10

    cv2.rectangle(frame, (bbox_x1, bbox_y1), (bbox_x2, bbox_y2), (255, 255, 0), 2)
    cv2.putText(
        frame,
        f"Hand: {hand_label}",
        (bbox_x1, bbox_y1 - 10),
        cv2.FONT_HERSHEY_SIMPLEX,
        0.5,
        (255, 255, 0),
        2,
    )

    # ç»˜åˆ¶å…³é”®ç‚¹
    for i, (dx, dy) in enumerate(hand_points):
        x = center_x + dx
        y = center_y + dy

        # ç»˜åˆ¶å…³é”®ç‚¹
        cv2.circle(frame, (x, y), 3, (0, 255, 255), -1)

        # ä¸ºé‡è¦å…³é”®ç‚¹æ·»åŠ æ ‡ç­¾
        if i in [4, 8, 12, 16, 20, 0]:
            point_names = {0: "è…•", 4: "æ‹‡æŒ‡", 8: "é£ŸæŒ‡", 12: "ä¸­æŒ‡", 16: "æ— åæŒ‡", 20: "å°æŒ‡"}
            if i in point_names:
                cv2.putText(
                    frame,
                    point_names[i],
                    (x + 5, y - 5),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.3,
                    (0, 255, 255),
                    1,
                )

    # ç»˜åˆ¶æ‰‹éƒ¨è¿æ¥çº¿
    # è¿æ¥æ‰‹è…•åˆ°å„æŒ‡æ ¹éƒ¨
    wrist = (center_x, center_y)
    finger_bases = [1, 5, 9, 13, 17]
    for base_idx in finger_bases:
        if base_idx < len(hand_points):
            dx, dy = hand_points[base_idx]
            base = (center_x + dx, center_y + dy)
            cv2.line(frame, wrist, base, (0, 255, 255), 1)

    # è¿æ¥å„æŒ‡å…³èŠ‚
    finger_connections = [
        [1, 2, 3, 4],  # æ‹‡æŒ‡
        [5, 6, 7, 8],  # é£ŸæŒ‡
        [9, 10, 11, 12],  # ä¸­æŒ‡
        [13, 14, 15, 16],  # æ— åæŒ‡
        [17, 18, 19, 20],  # å°æŒ‡
    ]

    for finger in finger_connections:
        for j in range(len(finger) - 1):
            if finger[j] < len(hand_points) and finger[j + 1] < len(hand_points):
                dx1, dy1 = hand_points[finger[j]]
                dx2, dy2 = hand_points[finger[j + 1]]
                pt1 = (center_x + dx1, center_y + dy1)
                pt2 = (center_x + dx2, center_y + dy2)
                cv2.line(frame, pt1, pt2, (0, 255, 255), 1)


def main():
    print("ğŸš€ å¯åŠ¨é™æ€å›¾åƒæ‰‹éƒ¨æ´—æ‰‹æ£€æµ‹æµ‹è¯•")
    print("æŒ‰ä»»æ„é”®ç»§ç»­ï¼ŒæŒ‰ 'q' é”®é€€å‡º")

    # åˆå§‹åŒ–æ£€æµ‹å™¨
    try:
        pose_detector = PoseDetector()
        behavior_recognizer = BehaviorRecognizer()
        human_detector = HumanDetector()
        print("âœ… æ£€æµ‹å™¨åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ£€æµ‹å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        return

    # åˆ›å»ºæµ‹è¯•å›¾åƒ
    print("ğŸ“¸ åˆ›å»ºæµ‹è¯•å›¾åƒ...")
    test_image = create_test_image()

    # ä¿å­˜åŸå§‹æµ‹è¯•å›¾åƒ
    cv2.imwrite("test_original.jpg", test_image)
    print("ğŸ’¾ åŸå§‹æµ‹è¯•å›¾åƒå·²ä¿å­˜: test_original.jpg")

    try:
        # äººä½“æ£€æµ‹
        print("ğŸ” æ‰§è¡Œäººä½“æ£€æµ‹...")
        person_detections = human_detector.detect(test_image)
        print(f"æ£€æµ‹åˆ° {len(person_detections)} ä¸ªäººä½“")

        # åˆ›å»ºæ£€æµ‹ç»“æœå¯¹è±¡
        result = DetectionResult(
            person_detections=person_detections,
            hairnet_results=[],
            handwash_results=[],
            sanitize_results=[],
            processing_times={"total": 0.0},
        )

        # åˆ›å»ºæ ‡æ³¨å›¾åƒ
        annotated_image = test_image.copy()

        # ç»˜åˆ¶äººä½“æ£€æµ‹æ¡†
        for i, person in enumerate(person_detections):
            bbox = person.get("bbox", [])
            if len(bbox) >= 4:
                x1, y1, x2, y2 = map(int, bbox[:4])
                confidence = person.get("confidence", 0)

                # ç»˜åˆ¶è¾¹ç•Œæ¡†
                cv2.rectangle(annotated_image, (x1, y1), (x2, y2), (0, 255, 0), 2)

                # ç»˜åˆ¶æ ‡ç­¾
                label = f"Person {confidence:.2f}"
                cv2.putText(
                    annotated_image,
                    label,
                    (x1, y1 - 10),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.5,
                    (0, 255, 0),
                    2,
                )

        # å¦‚æœæ£€æµ‹åˆ°äººä½“ï¼Œè¿›è¡ŒçœŸå®çš„æ´—æ‰‹è¡Œä¸ºæ£€æµ‹
        hands_count = 0
        handwash_detections = 0
        handwash_confidence = 0.0

        if person_detections:
            print("ğŸ” æ‰§è¡Œæ´—æ‰‹è¡Œä¸ºæ£€æµ‹...")

            for i, person in enumerate(person_detections):
                bbox = person.get("bbox", [])
                if len(bbox) >= 4:
                    x1, y1, x2, y2 = map(int, bbox[:4])
                    center_x = (x1 + x2) // 2
                    center_y = (y1 + y2) // 2

                    # æ¨¡æ‹Ÿæ‰‹éƒ¨åŒºåŸŸï¼ˆå®é™…åº”ç”¨ä¸­åº”è¯¥æ¥è‡ªæ‰‹éƒ¨æ£€æµ‹å™¨ï¼‰
                    hand_regions = [
                        {
                            "bbox": [
                                center_x - 80,
                                center_y - 40,
                                center_x - 40,
                                center_y,
                            ],
                            "confidence": 0.7,
                            "source": "simulated_left",
                        },
                        {
                            "bbox": [
                                center_x + 40,
                                center_y - 40,
                                center_x + 80,
                                center_y,
                            ],
                            "confidence": 0.8,
                            "source": "simulated_right",
                        },
                    ]
                    hands_count = len(hand_regions)

                    # ä½¿ç”¨è¡Œä¸ºè¯†åˆ«å™¨è¿›è¡ŒçœŸå®çš„æ´—æ‰‹æ£€æµ‹
                    handwash_confidence = behavior_recognizer.detect_handwashing(
                        person_bbox=bbox, hand_regions=hand_regions, frame=test_image
                    )

                    # åªæœ‰å½“ç½®ä¿¡åº¦è¶…è¿‡é˜ˆå€¼æ—¶æ‰è®¤ä¸ºæ˜¯æ´—æ‰‹è¡Œä¸º
                    if handwash_confidence > behavior_recognizer.confidence_threshold:
                        handwash_detections += 1

                        # ç»˜åˆ¶æ´—æ‰‹è¡Œä¸ºæ ‡ç­¾
                        cv2.putText(
                            annotated_image,
                            f"æ´—æ‰‹æ£€æµ‹ {handwash_confidence:.2f}",
                            (x1, y1 - 30),
                            cv2.FONT_HERSHEY_SIMPLEX,
                            0.6,
                            (0, 255, 0),
                            2,
                        )

                        # æ·»åŠ æ¼”ç¤ºæ‰‹éƒ¨å…³é”®ç‚¹ï¼ˆä»…åœ¨æ£€æµ‹åˆ°æ´—æ‰‹è¡Œä¸ºæ—¶ï¼‰
                        left_hand_x = center_x - 60
                        left_hand_y = center_y - 20
                        draw_hand_keypoints_demo(
                            annotated_image, left_hand_x, left_hand_y, "Left"
                        )

                        right_hand_x = center_x + 60
                        right_hand_y = center_y - 20
                        draw_hand_keypoints_demo(
                            annotated_image, right_hand_x, right_hand_y, "Right"
                        )
                    else:
                        # ç½®ä¿¡åº¦ä¸è¶³ï¼Œæ˜¾ç¤ºä¸ºæœªæ£€æµ‹åˆ°æ´—æ‰‹
                        cv2.putText(
                            annotated_image,
                            f"æœªæ£€æµ‹åˆ°æ´—æ‰‹ {handwash_confidence:.2f}",
                            (x1, y1 - 30),
                            cv2.FONT_HERSHEY_SIMPLEX,
                            0.6,
                            (0, 0, 255),
                            2,
                        )

                    # ç»˜åˆ¶æ‰‹éƒ¨åŒºåŸŸæ¡†
                    for hand_region in hand_regions:
                        hx1, hy1, hx2, hy2 = map(int, hand_region["bbox"])
                        cv2.rectangle(
                            annotated_image, (hx1, hy1), (hx2, hy2), (255, 0, 0), 1
                        )
                        cv2.putText(
                            annotated_image,
                            f"Hand {hand_region['confidence']:.2f}",
                            (hx1, hy1 - 5),
                            cv2.FONT_HERSHEY_SIMPLEX,
                            0.4,
                            (255, 0, 0),
                            1,
                        )

        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        info_lines = [
            f"æµ‹è¯•æ¨¡å¼: é™æ€å›¾åƒ",
            f"äººä½“: {len(person_detections)}",
            f"æ‰‹éƒ¨: {hands_count}",
            f"æ´—æ‰‹è¡Œä¸º: {handwash_detections}",
            f"ç½®ä¿¡åº¦: {handwash_confidence:.3f}",
        ]

        for i, info in enumerate(info_lines):
            cv2.putText(
                annotated_image,
                info,
                (10, 30 + i * 25),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.6,
                (255, 255, 255),
                2,
            )

        # æ·»åŠ æ“ä½œæç¤º
        cv2.putText(
            annotated_image,
            "æŒ‰ä»»æ„é”®ç»§ç»­, æŒ‰ 'q' é€€å‡º",
            (10, annotated_image.shape[0] - 20),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.5,
            (255, 255, 255),
            1,
        )

        # ä¿å­˜æ ‡æ³¨åçš„å›¾åƒ
        cv2.imwrite("test_annotated.jpg", annotated_image)
        print("ğŸ’¾ æ ‡æ³¨å›¾åƒå·²ä¿å­˜: test_annotated.jpg")

        # æ˜¾ç¤ºå›¾åƒ
        print("ğŸ–¼ï¸ æ˜¾ç¤ºæ£€æµ‹ç»“æœ...")
        cv2.imshow("æ‰‹éƒ¨æ´—æ‰‹æ£€æµ‹ç»“æœ", annotated_image)

        print("\nğŸ“Š æ£€æµ‹ç»“æœç»Ÿè®¡:")
        print(f"  - æ£€æµ‹åˆ°äººä½“: {len(person_detections)} ä¸ª")
        print(f"  - æ£€æµ‹åˆ°æ‰‹éƒ¨: {hands_count} ä¸ª")
        print(f"  - æ´—æ‰‹è¡Œä¸º: {handwash_detections} ä¸ª")
        print(f"  - æ£€æµ‹ç½®ä¿¡åº¦: {handwash_confidence:.3f}")
        print(f"  - ç½®ä¿¡åº¦é˜ˆå€¼: {behavior_recognizer.confidence_threshold:.3f}")
        print(f"  - æ´—æ‰‹åˆ¤å®š: {'æ˜¯' if handwash_detections > 0 else 'å¦'}")
        print("\nğŸ’¡ åŠŸèƒ½ç‰¹ç‚¹:")
        print("  - âœ… åŸºäºè¡Œä¸ºè¯†åˆ«å™¨çš„çœŸå®æ´—æ‰‹æ£€æµ‹")
        print("  - âœ… ç½®ä¿¡åº¦é˜ˆå€¼åˆ¤å®šæœºåˆ¶")
        print("  - âœ… åªåœ¨ç¡®è®¤æ´—æ‰‹è¡Œä¸ºæ—¶æ˜¾ç¤ºæ‰‹éƒ¨å…³é”®ç‚¹")
        print("  - âœ… æ”¯æŒå¤šæ‰‹æ£€æµ‹å’Œå·¦å³æ‰‹åŒºåˆ†")
        print("  - âœ… 21ä¸ªå…³é”®ç‚¹æ ‡æ³¨")
        print("  - âœ… æ˜¾ç¤ºæ‰‹éƒ¨è¾¹ç•Œæ¡†å’Œç½®ä¿¡åº¦")
        print("  - âœ… ç»˜åˆ¶æ‰‹éƒ¨éª¨æ¶è¿æ¥çº¿")
        print("  - âœ… å®æ—¶æ˜¾ç¤ºæ£€æµ‹ç»Ÿè®¡ä¿¡æ¯")

        # ç­‰å¾…ç”¨æˆ·æŒ‰é”®
        while True:
            key = cv2.waitKey(0) & 0xFF
            if key == ord("q"):
                print("ğŸ‘‹ ç”¨æˆ·é€€å‡º")
                break
            else:
                print("ğŸ”„ ç»§ç»­æ˜¾ç¤º...")

    except Exception as e:
        print(f"âš ï¸ å¤„ç†å›¾åƒæ—¶å‡ºé”™: {e}")
        # æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
        error_image = test_image.copy()
        cv2.putText(
            error_image,
            f"Error: {str(e)[:50]}",
            (10, 50),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.5,
            (0, 0, 255),
            2,
        )
        cv2.imshow("é”™è¯¯ä¿¡æ¯", error_image)
        cv2.waitKey(0)

    # æ¸…ç†èµ„æº
    cv2.destroyAllWindows()
    print("âœ… æµ‹è¯•å®Œæˆ")


if __name__ == "__main__":
    main()
