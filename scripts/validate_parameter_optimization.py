#!/usr/bin/env python3
"""
å‚æ•°ä¼˜åŒ–éªŒè¯è„šæœ¬
éªŒè¯ç»Ÿä¸€å‚æ•°é…ç½®çš„æ•ˆæœå’Œä¸€è‡´æ€§

åŠŸèƒ½:
1. éªŒè¯æ‰€æœ‰æ¨¡å—ä½¿ç”¨ç»Ÿä¸€å‚æ•°é…ç½®
2. æ£€æŸ¥å‚æ•°ä¸€è‡´æ€§
3. æ€§èƒ½åŸºå‡†æµ‹è¯•
4. ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š

ä½œè€…: AI Assistant
åˆ›å»ºæ—¶é—´: 2024
"""

import logging
import os
import sys
import time
from pathlib import Path
from typing import Any, Dict, List, Tuple

import numpy as np

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

from src.config.unified_params import get_unified_params
from src.core.behavior import BehaviorRecognizer
from src.core.detector import HumanDetector
from src.core.hairnet_detector import HairnetDetector

logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


class ParameterOptimizationValidator:
    """å‚æ•°ä¼˜åŒ–éªŒè¯å™¨"""

    def __init__(self):
        self.unified_params = get_unified_params()
        self.validation_results = {
            "parameter_consistency": {},
            "module_initialization": {},
            "performance_metrics": {},
            "recommendations": [],
        }

    def validate_parameter_consistency(self) -> Dict[str, Any]:
        """éªŒè¯å‚æ•°ä¸€è‡´æ€§"""
        logger.info("éªŒè¯å‚æ•°ä¸€è‡´æ€§...")

        consistency_results = {
            "unified_config_loaded": False,
            "parameter_values": {},
            "consistency_issues": [],
        }

        try:
            # éªŒè¯ç»Ÿä¸€é…ç½®æ˜¯å¦æ­£ç¡®åŠ è½½
            params = self.unified_params
            consistency_results["unified_config_loaded"] = True

            # è®°å½•å…³é”®å‚æ•°å€¼
            consistency_results["parameter_values"] = {
                "human_detection_confidence": params.human_detection.confidence_threshold,
                "human_detection_iou": params.human_detection.iou_threshold,
                "human_detection_min_area": params.human_detection.min_box_area,
                "hairnet_detection_confidence": params.hairnet_detection.confidence_threshold,
                "hairnet_edge_density_threshold": params.hairnet_detection.edge_density_threshold,
                "behavior_recognition_confidence": params.behavior_recognition.confidence_threshold,
                "handwashing_min_duration": params.behavior_recognition.handwashing_min_duration,
                "hairnet_min_duration": params.behavior_recognition.hairnet_min_duration,
            }

            # æ£€æŸ¥å‚æ•°åˆç†æ€§
            if (
                params.human_detection.confidence_threshold <= 0
                or params.human_detection.confidence_threshold >= 1
            ):
                consistency_results["consistency_issues"].append("äººä½“æ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼ä¸åœ¨åˆç†èŒƒå›´å†…")

            if (
                params.hairnet_detection.confidence_threshold <= 0
                or params.hairnet_detection.confidence_threshold >= 1
            ):
                consistency_results["consistency_issues"].append("å‘ç½‘æ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼ä¸åœ¨åˆç†èŒƒå›´å†…")

            if (
                params.behavior_recognition.confidence_threshold <= 0
                or params.behavior_recognition.confidence_threshold >= 1
            ):
                consistency_results["consistency_issues"].append("è¡Œä¸ºè¯†åˆ«ç½®ä¿¡åº¦é˜ˆå€¼ä¸åœ¨åˆç†èŒƒå›´å†…")

            if params.behavior_recognition.handwashing_min_duration <= 0:
                consistency_results["consistency_issues"].append("æ´—æ‰‹æœ€å°æŒç»­æ—¶é—´è®¾ç½®ä¸åˆç†")

            logger.info(
                f"å‚æ•°ä¸€è‡´æ€§éªŒè¯å®Œæˆï¼Œå‘ç° {len(consistency_results['consistency_issues'])} ä¸ªé—®é¢˜"
            )

        except Exception as e:
            logger.error(f"å‚æ•°ä¸€è‡´æ€§éªŒè¯å¤±è´¥: {e}")
            consistency_results["unified_config_loaded"] = False

        self.validation_results["parameter_consistency"] = consistency_results
        return consistency_results

    def validate_module_initialization(self) -> Dict[str, Any]:
        """éªŒè¯æ¨¡å—åˆå§‹åŒ–"""
        logger.info("éªŒè¯æ¨¡å—åˆå§‹åŒ–...")

        initialization_results = {
            "human_detector": {"success": False, "error": None, "params_used": {}},
            "hairnet_detector": {"success": False, "error": None, "params_used": {}},
            "behavior_recognizer": {"success": False, "error": None, "params_used": {}},
        }

        # æµ‹è¯•äººä½“æ£€æµ‹å™¨åˆå§‹åŒ–
        try:
            detector = HumanDetector()
            initialization_results["human_detector"]["success"] = True
            initialization_results["human_detector"]["params_used"] = {
                "confidence_threshold": detector.confidence_threshold,
                "iou_threshold": detector.iou_threshold,
                "min_box_area": detector.min_box_area,
            }
            logger.info("äººä½“æ£€æµ‹å™¨åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            initialization_results["human_detector"]["error"] = str(e)
            logger.error(f"äººä½“æ£€æµ‹å™¨åˆå§‹åŒ–å¤±è´¥: {e}")

        # æµ‹è¯•å‘ç½‘æ£€æµ‹å™¨åˆå§‹åŒ–
        try:
            hairnet_detector = HairnetDetector()
            initialization_results["hairnet_detector"]["success"] = True
            initialization_results["hairnet_detector"]["params_used"] = {
                "confidence_threshold": hairnet_detector.confidence_threshold
            }
            logger.info("å‘ç½‘æ£€æµ‹å™¨åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            initialization_results["hairnet_detector"]["error"] = str(e)
            logger.error(f"å‘ç½‘æ£€æµ‹å™¨åˆå§‹åŒ–å¤±è´¥: {e}")

        # æµ‹è¯•è¡Œä¸ºè¯†åˆ«å™¨åˆå§‹åŒ–
        try:
            behavior_recognizer = BehaviorRecognizer()
            initialization_results["behavior_recognizer"]["success"] = True
            initialization_results["behavior_recognizer"]["params_used"] = {
                "confidence_threshold": behavior_recognizer.confidence_threshold
            }
            logger.info("è¡Œä¸ºè¯†åˆ«å™¨åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            initialization_results["behavior_recognizer"]["error"] = str(e)
            logger.error(f"è¡Œä¸ºè¯†åˆ«å™¨åˆå§‹åŒ–å¤±è´¥: {e}")

        self.validation_results["module_initialization"] = initialization_results
        return initialization_results

    def run_performance_benchmark(self) -> Dict[str, Any]:
        """è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•"""
        logger.info("è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•...")

        performance_results = {
            "initialization_time": {},
            "memory_usage": {},
            "parameter_access_time": {},
        }

        # æµ‹è¯•åˆå§‹åŒ–æ—¶é—´
        try:
            # äººä½“æ£€æµ‹å™¨åˆå§‹åŒ–æ—¶é—´
            start_time = time.time()
            detector = HumanDetector()
            init_time = time.time() - start_time
            performance_results["initialization_time"]["human_detector"] = init_time

            # å‘ç½‘æ£€æµ‹å™¨åˆå§‹åŒ–æ—¶é—´
            start_time = time.time()
            hairnet_detector = HairnetDetector()
            init_time = time.time() - start_time
            performance_results["initialization_time"]["hairnet_detector"] = init_time

            # è¡Œä¸ºè¯†åˆ«å™¨åˆå§‹åŒ–æ—¶é—´
            start_time = time.time()
            behavior_recognizer = BehaviorRecognizer()
            init_time = time.time() - start_time
            performance_results["initialization_time"][
                "behavior_recognizer"
            ] = init_time

            logger.info("æ€§èƒ½åŸºå‡†æµ‹è¯•å®Œæˆ")

        except Exception as e:
            logger.error(f"æ€§èƒ½åŸºå‡†æµ‹è¯•å¤±è´¥: {e}")

        # æµ‹è¯•å‚æ•°è®¿é—®æ—¶é—´
        try:
            start_time = time.time()
            for _ in range(1000):
                params = get_unified_params()
                _ = params.human_detection.confidence_threshold
                _ = params.hairnet_detection.confidence_threshold
                _ = params.behavior_recognition.confidence_threshold
            access_time = (time.time() - start_time) / 1000
            performance_results["parameter_access_time"]["avg_per_access"] = access_time

        except Exception as e:
            logger.error(f"å‚æ•°è®¿é—®æ—¶é—´æµ‹è¯•å¤±è´¥: {e}")

        self.validation_results["performance_metrics"] = performance_results
        return performance_results

    def generate_recommendations(self) -> List[str]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []

        # åŸºäºéªŒè¯ç»“æœç”Ÿæˆå»ºè®®
        consistency = self.validation_results.get("parameter_consistency", {})
        initialization = self.validation_results.get("module_initialization", {})
        performance = self.validation_results.get("performance_metrics", {})

        if not consistency.get("unified_config_loaded", False):
            recommendations.append("ç»Ÿä¸€å‚æ•°é…ç½®åŠ è½½å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥é…ç½®æ–‡ä»¶")

        if consistency.get("consistency_issues"):
            recommendations.append(
                f"å‘ç° {len(consistency['consistency_issues'])} ä¸ªå‚æ•°ä¸€è‡´æ€§é—®é¢˜ï¼Œéœ€è¦è°ƒæ•´å‚æ•°å€¼"
            )

        # æ£€æŸ¥æ¨¡å—åˆå§‹åŒ–æˆåŠŸç‡
        failed_modules = []
        for module, result in initialization.items():
            if not result.get("success", False):
                failed_modules.append(module)

        if failed_modules:
            recommendations.append(f"ä»¥ä¸‹æ¨¡å—åˆå§‹åŒ–å¤±è´¥: {', '.join(failed_modules)}ï¼Œéœ€è¦æ£€æŸ¥ä¾èµ–å’Œé…ç½®")

        # æ€§èƒ½å»ºè®®
        init_times = performance.get("initialization_time", {})
        if init_times:
            max_init_time = max(init_times.values())
            if max_init_time > 5.0:  # è¶…è¿‡5ç§’
                recommendations.append("æ¨¡å—åˆå§‹åŒ–æ—¶é—´è¾ƒé•¿ï¼Œè€ƒè™‘ä¼˜åŒ–æ¨¡å‹åŠ è½½æˆ–ä½¿ç”¨å»¶è¿ŸåŠ è½½")

        # å‚æ•°ä¼˜åŒ–å»ºè®®
        param_values = consistency.get("parameter_values", {})
        if param_values:
            human_conf = param_values.get("human_detection_confidence", 0)
            hairnet_conf = param_values.get("hairnet_detection_confidence", 0)

            if abs(human_conf - hairnet_conf) > 0.3:
                recommendations.append("äººä½“æ£€æµ‹å’Œå‘ç½‘æ£€æµ‹çš„ç½®ä¿¡åº¦é˜ˆå€¼å·®å¼‚è¾ƒå¤§ï¼Œå»ºè®®è°ƒæ•´ä»¥ä¿æŒä¸€è‡´æ€§")

            if human_conf < 0.2:
                recommendations.append("äººä½“æ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼è¾ƒä½ï¼Œå¯èƒ½å¯¼è‡´è¯¯æ£€ï¼Œå»ºè®®é€‚å½“æé«˜")

            if hairnet_conf > 0.8:
                recommendations.append("å‘ç½‘æ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼è¾ƒé«˜ï¼Œå¯èƒ½å¯¼è‡´æ¼æ£€ï¼Œå»ºè®®é€‚å½“é™ä½")

        if not recommendations:
            recommendations.append("å‚æ•°ä¼˜åŒ–éªŒè¯é€šè¿‡ï¼Œç³»ç»Ÿé…ç½®è‰¯å¥½")

        self.validation_results["recommendations"] = recommendations
        return recommendations

    def generate_report(self) -> str:
        """ç”ŸæˆéªŒè¯æŠ¥å‘Š"""
        report = []
        report.append("# å‚æ•°ä¼˜åŒ–éªŒè¯æŠ¥å‘Š")
        report.append("")
        report.append(f"## éªŒè¯æ¦‚è¦")

        # å‚æ•°ä¸€è‡´æ€§
        consistency = self.validation_results.get("parameter_consistency", {})
        report.append(
            f"- ç»Ÿä¸€é…ç½®åŠ è½½: {'âœ… æˆåŠŸ' if consistency.get('unified_config_loaded') else 'âŒ å¤±è´¥'}"
        )
        report.append(f"- ä¸€è‡´æ€§é—®é¢˜: {len(consistency.get('consistency_issues', []))}ä¸ª")

        # æ¨¡å—åˆå§‹åŒ–
        initialization = self.validation_results.get("module_initialization", {})
        success_count = sum(
            1 for result in initialization.values() if result.get("success", False)
        )
        total_count = len(initialization)
        report.append(f"- æ¨¡å—åˆå§‹åŒ–æˆåŠŸç‡: {success_count}/{total_count}")

        report.append("")

        # è¯¦ç»†å‚æ•°å€¼
        if consistency.get("parameter_values"):
            report.append("## å½“å‰å‚æ•°é…ç½®")
            for param_name, param_value in consistency["parameter_values"].items():
                report.append(f"- {param_name}: {param_value}")
            report.append("")

        # ä¸€è‡´æ€§é—®é¢˜
        if consistency.get("consistency_issues"):
            report.append("## å‘ç°çš„é—®é¢˜")
            for issue in consistency["consistency_issues"]:
                report.append(f"- âŒ {issue}")
            report.append("")

        # æ¨¡å—åˆå§‹åŒ–è¯¦æƒ…
        report.append("## æ¨¡å—åˆå§‹åŒ–çŠ¶æ€")
        for module, result in initialization.items():
            status = (
                "âœ… æˆåŠŸ"
                if result.get("success")
                else f"âŒ å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"
            )
            report.append(f"- {module}: {status}")
        report.append("")

        # æ€§èƒ½æŒ‡æ ‡
        performance = self.validation_results.get("performance_metrics", {})
        if performance.get("initialization_time"):
            report.append("## æ€§èƒ½æŒ‡æ ‡")
            report.append("### åˆå§‹åŒ–æ—¶é—´")
            for module, time_taken in performance["initialization_time"].items():
                report.append(f"- {module}: {time_taken:.3f}ç§’")

            if performance.get("parameter_access_time", {}).get("avg_per_access"):
                avg_access_time = performance["parameter_access_time"]["avg_per_access"]
                report.append(f"- å‚æ•°è®¿é—®å¹³å‡æ—¶é—´: {avg_access_time*1000:.3f}æ¯«ç§’")
            report.append("")

        # å»ºè®®
        recommendations = self.validation_results.get("recommendations", [])
        if recommendations:
            report.append("## ä¼˜åŒ–å»ºè®®")
            for i, recommendation in enumerate(recommendations, 1):
                report.append(f"{i}. {recommendation}")
            report.append("")

        report.append("## æ€»ç»“")
        if consistency.get("unified_config_loaded") and success_count == total_count:
            report.append("âœ… å‚æ•°ç»Ÿä¸€ä¼˜åŒ–æˆåŠŸï¼Œæ‰€æœ‰æ¨¡å—æ­£å¸¸å·¥ä½œ")
        else:
            report.append("âš ï¸ å‚æ•°ç»Ÿä¸€ä¼˜åŒ–éƒ¨åˆ†æˆåŠŸï¼Œå­˜åœ¨éœ€è¦è§£å†³çš„é—®é¢˜")

        return "\n".join(report)

    def run_full_validation(self) -> bool:
        """è¿è¡Œå®Œæ•´éªŒè¯æµç¨‹"""
        logger.info("å¼€å§‹å‚æ•°ä¼˜åŒ–éªŒè¯")

        try:
            # 1. éªŒè¯å‚æ•°ä¸€è‡´æ€§
            self.validate_parameter_consistency()

            # 2. éªŒè¯æ¨¡å—åˆå§‹åŒ–
            self.validate_module_initialization()

            # 3. è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•
            self.run_performance_benchmark()

            # 4. ç”Ÿæˆå»ºè®®
            self.generate_recommendations()

            # 5. ç”ŸæˆæŠ¥å‘Š
            report = self.generate_report()
            report_path = project_root / "parameter_optimization_validation_report.md"
            with open(report_path, "w", encoding="utf-8") as f:
                f.write(report)

            logger.info(f"éªŒè¯å®Œæˆï¼ŒæŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
            return True

        except Exception as e:
            logger.error(f"éªŒè¯æµç¨‹å¤±è´¥: {e}")
            return False


def main():
    """ä¸»å‡½æ•°"""
    print("=== å‚æ•°ä¼˜åŒ–éªŒè¯å·¥å…· ===")
    print("æ­¤å·¥å…·å°†éªŒè¯ç»Ÿä¸€å‚æ•°é…ç½®çš„æ•ˆæœå’Œä¸€è‡´æ€§")
    print()

    validator = ParameterOptimizationValidator()

    # è¿è¡ŒéªŒè¯
    success = validator.run_full_validation()

    if success:
        print("\nâœ… éªŒè¯å®Œæˆ!")
        print("\næŸ¥çœ‹è¯¦ç»†æŠ¥å‘Š: parameter_optimization_validation_report.md")

        # æ˜¾ç¤ºå…³é”®ç»“æœ
        consistency = validator.validation_results.get("parameter_consistency", {})
        if consistency.get("unified_config_loaded"):
            print("\nğŸ“Š å½“å‰å‚æ•°é…ç½®:")
            for param, value in consistency.get("parameter_values", {}).items():
                print(f"  - {param}: {value}")

        recommendations = validator.validation_results.get("recommendations", [])
        if recommendations:
            print("\nğŸ’¡ ä¸»è¦å»ºè®®:")
            for rec in recommendations[:3]:  # æ˜¾ç¤ºå‰3ä¸ªå»ºè®®
                print(f"  - {rec}")
    else:
        print("\nâŒ éªŒè¯å¤±è´¥ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—äº†è§£è¯¦æƒ…")


if __name__ == "__main__":
    main()
