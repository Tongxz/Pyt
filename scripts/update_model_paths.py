#!/usr/bin/env python3
"""
æ¨¡å‹è·¯å¾„æ›´æ–°è„šæœ¬

è¯¥è„šæœ¬ç”¨äºæ›´æ–°é¡¹ç›®ä¸­æ‰€æœ‰æ¨¡å‹æ–‡ä»¶çš„è·¯å¾„å¼•ç”¨ï¼Œ
å°†æ—§çš„è·¯å¾„æ›´æ–°ä¸ºæ–°çš„modelsç›®å½•ç»“æ„ã€‚

ä½¿ç”¨æ–¹æ³•:
    python scripts/update_model_paths.py
"""

import logging
import os
import re
from pathlib import Path
from typing import Dict, List, Tuple

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


class ModelPathUpdater:
    """æ¨¡å‹è·¯å¾„æ›´æ–°å™¨"""

    def __init__(self, project_root: str | None = None):
        self.project_root = Path(project_root) if project_root else Path.cwd()

        # è·¯å¾„æ˜ å°„è§„åˆ™
        self.path_mappings = {
            # YOLOæ¨¡å‹è·¯å¾„æ˜ å°„
            r"yolov8n\.pt": "models/yolo/models/yolo/yolov8n.pt",
            r"yolov8s\.pt": "models/yolo/models/yolo/yolov8s.pt",
            r"yolov8m\.pt": "models/yolo/models/yolo/yolov8m.pt",
            r"yolov8l\.pt": "models/yolo/models/yolo/yolov8l.pt",
            # å‘ç½‘æ£€æµ‹æ¨¡å‹è·¯å¾„æ˜ å°„
            r"models/hairnet_detection\.pt": "models/hairnet_detection/models/hairnet_detection/hairnet_detection.pt",
            r"hairnet_detection\.pt": "models/hairnet_detection/models/hairnet_detection/hairnet_detection.pt",
            # ç”¨æˆ·è®­ç»ƒæ¨¡å‹è·¯å¾„ï¼ˆä¿æŒä¸å˜ï¼Œä½†éœ€è¦ç¡®ä¿å¼•ç”¨æ­£ç¡®ï¼‰
            r"models/hairnet_model/weights/best\.pt": "models/hairnet_model/weights/best.pt",
            r"models/hairnet_model/weights/last\.pt": "models/hairnet_model/weights/last.pt",
            # å…¶ä»–æ¨¡å‹è·¯å¾„
            r"models/yolov8n\.pt": "models/yolo/models/yolo/yolov8n.pt",
            r"models/yolov8s\.pt": "models/yolo/models/yolo/yolov8s.pt",
            r"models/yolov8m\.pt": "models/yolo/models/yolo/yolov8m.pt",
            r"models/yolov8l\.pt": "models/yolo/models/yolo/yolov8l.pt",
        }

        # éœ€è¦æ›´æ–°çš„æ–‡ä»¶ç±»å‹
        self.file_extensions = {".py", ".yaml", ".yml", ".md", ".sh", ".ps1", ".bat"}

        # éœ€è¦æ’é™¤çš„ç›®å½•
        self.exclude_dirs = {
            ".git",
            ".venv",
            "venv",
            "__pycache__",
            ".pytest_cache",
            "node_modules",
            ".tox",
            "logs",
            "temp",
        }

        # æ›´æ–°ç»Ÿè®¡
        self.update_stats = {
            "files_processed": 0,
            "files_updated": 0,
            "total_replacements": 0,
            "replacements_by_file": {},
        }

    def should_process_file(self, file_path: Path) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥å¤„ç†è¯¥æ–‡ä»¶"""
        # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
        if file_path.suffix not in self.file_extensions:
            return False

        # æ£€æŸ¥æ˜¯å¦åœ¨æ’é™¤ç›®å½•ä¸­
        for exclude_dir in self.exclude_dirs:
            if exclude_dir in file_path.parts:
                return False

        return True

    def update_file_content(self, file_path: Path) -> bool:
        """æ›´æ–°å•ä¸ªæ–‡ä»¶çš„å†…å®¹"""
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read()

            original_content = content
            replacements_made = 0

            # åº”ç”¨æ‰€æœ‰è·¯å¾„æ˜ å°„
            for old_pattern, new_path in self.path_mappings.items():
                # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è¿›è¡Œæ›¿æ¢
                matches = re.findall(old_pattern, content)
                if matches:
                    content = re.sub(old_pattern, new_path, content)
                    replacements_made += len(matches)
                    logger.info(
                        f"åœ¨ {file_path} ä¸­æ›¿æ¢äº† {len(matches)} ä¸ª '{old_pattern}' -> '{new_path}'"
                    )

            # å¦‚æœæœ‰æ›´æ”¹ï¼Œå†™å›æ–‡ä»¶
            if content != original_content:
                with open(file_path, "w", encoding="utf-8") as f:
                    f.write(content)

                self.update_stats["files_updated"] += 1
                self.update_stats["total_replacements"] += replacements_made
                self.update_stats["replacements_by_file"][
                    str(file_path)
                ] = replacements_made

                logger.info(f"âœ… æ›´æ–°æ–‡ä»¶: {file_path} ({replacements_made} ä¸ªæ›¿æ¢)")
                return True

            return False

        except Exception as e:
            logger.error(f"âŒ å¤„ç†æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
            return False

    def find_files_to_update(self) -> List[Path]:
        """æŸ¥æ‰¾éœ€è¦æ›´æ–°çš„æ–‡ä»¶"""
        files_to_update = []

        for root, dirs, files in os.walk(self.project_root):
            # æ’é™¤ä¸éœ€è¦çš„ç›®å½•
            dirs[:] = [d for d in dirs if d not in self.exclude_dirs]

            for file in files:
                file_path = Path(root) / file
                if self.should_process_file(file_path):
                    files_to_update.append(file_path)

        return files_to_update

    def update_all_paths(self) -> None:
        """æ›´æ–°æ‰€æœ‰æ¨¡å‹è·¯å¾„"""
        logger.info("å¼€å§‹æ›´æ–°æ¨¡å‹è·¯å¾„...")
        logger.info(f"é¡¹ç›®æ ¹ç›®å½•: {self.project_root}")

        # æŸ¥æ‰¾éœ€è¦æ›´æ–°çš„æ–‡ä»¶
        files_to_update = self.find_files_to_update()
        logger.info(f"æ‰¾åˆ° {len(files_to_update)} ä¸ªæ–‡ä»¶éœ€è¦æ£€æŸ¥")

        # æ›´æ–°æ¯ä¸ªæ–‡ä»¶
        for file_path in files_to_update:
            self.update_stats["files_processed"] += 1
            self.update_file_content(file_path)

        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        self.print_update_summary()

    def print_update_summary(self) -> None:
        """æ‰“å°æ›´æ–°æ‘˜è¦"""
        logger.info("\n" + "=" * 60)
        logger.info("æ¨¡å‹è·¯å¾„æ›´æ–°å®Œæˆ")
        logger.info("=" * 60)
        logger.info(f"å¤„ç†æ–‡ä»¶æ•°: {self.update_stats['files_processed']}")
        logger.info(f"æ›´æ–°æ–‡ä»¶æ•°: {self.update_stats['files_updated']}")
        logger.info(f"æ€»æ›¿æ¢æ¬¡æ•°: {self.update_stats['total_replacements']}")

        if self.update_stats["replacements_by_file"]:
            logger.info("\nè¯¦ç»†æ›´æ–°ä¿¡æ¯:")
            for file_path, count in self.update_stats["replacements_by_file"].items():
                logger.info(f"  {file_path}: {count} ä¸ªæ›¿æ¢")

        logger.info("\nè·¯å¾„æ˜ å°„è§„åˆ™:")
        for old_pattern, new_path in self.path_mappings.items():
            logger.info(f"  {old_pattern} -> {new_path}")

    def validate_model_paths(self) -> None:
        """éªŒè¯æ›´æ–°åçš„æ¨¡å‹è·¯å¾„æ˜¯å¦æ­£ç¡®"""
        logger.info("\néªŒè¯æ¨¡å‹è·¯å¾„...")

        # æ£€æŸ¥å…³é”®æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        key_models = [
            "models/yolo/models/yolo/yolov8n.pt",
            "models/yolo/models/yolo/yolov8s.pt",
            "models/yolo/models/yolo/yolov8m.pt",
            "models/yolo/models/yolo/yolov8l.pt",
            "models/hairnet_detection/models/hairnet_detection/hairnet_detection.pt",
            "models/hairnet_model/weights/best.pt",
            "models/hairnet_model/weights/last.pt",
        ]

        existing_models = []
        missing_models = []

        for model_path in key_models:
            full_path = self.project_root / model_path
            if full_path.exists():
                size_mb = full_path.stat().st_size / (1024 * 1024)
                existing_models.append(f"{model_path} ({size_mb:.1f} MB)")
            else:
                missing_models.append(model_path)

        if existing_models:
            logger.info("âœ… å­˜åœ¨çš„æ¨¡å‹æ–‡ä»¶:")
            for model in existing_models:
                logger.info(f"  {model}")

        if missing_models:
            logger.warning("âš ï¸  ç¼ºå¤±çš„æ¨¡å‹æ–‡ä»¶:")
            for model in missing_models:
                logger.warning(f"  {model}")
            logger.warning("è¯·ç¡®ä¿è¿™äº›æ¨¡å‹æ–‡ä»¶å·²æ­£ç¡®ç§»åŠ¨åˆ°æ–°ä½ç½®")

    def create_update_report(self) -> None:
        """åˆ›å»ºæ›´æ–°æŠ¥å‘Š"""
        report_path = self.project_root / "reports" / "model_path_update_report.md"
        report_path.parent.mkdir(exist_ok=True)

        report_content = f"""# æ¨¡å‹è·¯å¾„æ›´æ–°æŠ¥å‘Š

**ç”Ÿæˆæ—¶é—´**: {self.get_current_time()}
**æ“ä½œç±»å‹**: æ¨¡å‹è·¯å¾„æ›´æ–°

## æ›´æ–°æ‘˜è¦

- **å¤„ç†æ–‡ä»¶æ•°**: {self.update_stats['files_processed']}
- **æ›´æ–°æ–‡ä»¶æ•°**: {self.update_stats['files_updated']}
- **æ€»æ›¿æ¢æ¬¡æ•°**: {self.update_stats['total_replacements']}

## è·¯å¾„æ˜ å°„è§„åˆ™

| æ—§è·¯å¾„æ¨¡å¼ | æ–°è·¯å¾„ |
|-----------|--------|
"""

        for old_pattern, new_path in self.path_mappings.items():
            report_content += f"| `{old_pattern}` | `{new_path}` |\n"

        if self.update_stats["replacements_by_file"]:
            report_content += "\n## è¯¦ç»†æ›´æ–°ä¿¡æ¯\n\n"
            for file_path, count in self.update_stats["replacements_by_file"].items():
                relative_path = Path(file_path).relative_to(self.project_root)
                report_content += f"- `{relative_path}`: {count} ä¸ªæ›¿æ¢\n"

        report_content += "\n## æ³¨æ„äº‹é¡¹\n\n"
        report_content += "1. æ‰€æœ‰YOLOæ¨¡å‹ç°åœ¨ä½äº `models/yolo/` ç›®å½•ä¸‹\n"
        report_content += "2. å‘ç½‘æ£€æµ‹æ¨¡å‹ä½äº `models/hairnet_detection/` ç›®å½•ä¸‹\n"
        report_content += "3. ç”¨æˆ·è®­ç»ƒçš„æ¨¡å‹ä»åœ¨ `models/hairnet_model/weights/` ç›®å½•ä¸‹ï¼ˆå—ä¿æŠ¤ï¼‰\n"
        report_content += "4. è¯·ç¡®ä¿æ‰€æœ‰æ¨¡å‹æ–‡ä»¶å·²æ­£ç¡®ç§»åŠ¨åˆ°æ–°ä½ç½®\n"
        report_content += "5. å¦‚æœ‰é…ç½®æ–‡ä»¶ç¼“å­˜ï¼Œè¯·æ¸…é™¤åé‡æ–°åŠ è½½\n"

        with open(report_path, "w", encoding="utf-8") as f:
            f.write(report_content)

        logger.info(f"\nğŸ“„ æ›´æ–°æŠ¥å‘Šå·²ä¿å­˜: {report_path}")

    def get_current_time(self) -> str:
        """è·å–å½“å‰æ—¶é—´å­—ç¬¦ä¸²"""
        from datetime import datetime

        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")


def main():
    """ä¸»å‡½æ•°"""
    try:
        # åˆ›å»ºæ›´æ–°å™¨å®ä¾‹
        updater = ModelPathUpdater()

        # æ‰§è¡Œè·¯å¾„æ›´æ–°
        updater.update_all_paths()

        # éªŒè¯æ¨¡å‹è·¯å¾„
        updater.validate_model_paths()

        # åˆ›å»ºæ›´æ–°æŠ¥å‘Š
        updater.create_update_report()

        logger.info("\nğŸ‰ æ¨¡å‹è·¯å¾„æ›´æ–°å®Œæˆï¼")
        logger.info("è¯·æ£€æŸ¥æ›´æ–°æŠ¥å‘Šä»¥ç¡®è®¤æ‰€æœ‰æ›´æ”¹éƒ½æ­£ç¡®åº”ç”¨ã€‚")

    except Exception as e:
        logger.error(f"âŒ æ›´æ–°è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        raise


if __name__ == "__main__":
    main()
